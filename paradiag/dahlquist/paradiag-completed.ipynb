{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32e18e20",
   "metadata": {},
   "source": [
    "# Dalhquist's ODE using a parallel-in-time method\n",
    "\n",
    "Now that we are familiar with Dalhquist's model ODE, we will solve it using the parallel-in-time method ParaDiag.\n",
    "First, we rewrite Dalhquist's ODE to separate the terms including the solution $q$ on the left hand side, and the forcing term $b$ on the right hand side:\n",
    "\n",
    "$$\n",
    "\\partial_{t}q(t) - \\lambda q(t) = b(t)\n",
    "$$\n",
    "\n",
    "The implicit theta method discretisation then looks like:\n",
    "\n",
    "$$\n",
    "\\frac{q^{n+1}-q^{n}}{\\Delta t} - (\\theta\\lambda q^{n+1} + (1-\\theta)\\lambda q^{n}) = \\theta b(t^{n+1}) + (1-\\theta)b(t^{n})\n",
    "$$\n",
    "\n",
    "We can now construct the all-at-once system which couples all timesteps in the time-series together into a single problem. For 4 timesteps this looks like:\n",
    "\n",
    "$$\n",
    "\\left(\n",
    "\\frac{1}{\\Delta t}\n",
    "\\begin{pmatrix}\n",
    " 1 &  0 &  0 & 0 \\\\\n",
    "-1 &  1 &  0 & 0 \\\\\n",
    " 0 & -1 &  1 & 0 \\\\\n",
    " 0 &  0 & -1 & 1 \\\\\n",
    "\\end{pmatrix}\n",
    "-\n",
    "\\lambda\n",
    "\\begin{pmatrix}\n",
    "\\theta     & 0          & 0          & 0 \\\\\n",
    "(1-\\theta) & \\theta     & 0          & 0 \\\\\n",
    "0          & (1-\\theta) & \\theta     & 0 \\\\\n",
    "0          & 0          & (1-\\theta) & \\theta \\\\\n",
    "\\end{pmatrix}\n",
    "\\right)\n",
    "\\begin{pmatrix}\n",
    "q^{1} \\\\ q^{2} \\\\ q^{3} \\\\ q^{4} \\\\\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\textbf{b}\n",
    "$$\n",
    "\n",
    "The left hand side can be written using the two Toeplitz matrices $\\textbf{B}_{1}$ and $\\textbf{B}_{2}$ which define the implicit theta method:\n",
    "\n",
    "$$\n",
    "\\textbf{A}\\textbf{q} = \\left(\\frac{1}{\\Delta t}\\textbf{B}_{1} - \\lambda\\textbf{B}_{2}\\right)\\textbf{q}\n",
    "$$\n",
    "\n",
    "Where $\\textbf{A}$ is the all-at-once Jacobian, and $\\textbf{q}$ is the vector of the timeseries $q^{n}$.\n",
    "\n",
    "The right hand side vector $\\textbf{b}$ contains the forcing terms and the initial condition:\n",
    "\n",
    "$$\n",
    "\\theta\n",
    "\\begin{pmatrix}\n",
    "b(t^{1}) \\\\\n",
    "b(t^{2}) \\\\\n",
    "b(t^{3}) \\\\\n",
    "b(t^{4}) \\\\\n",
    "\\end{pmatrix}\n",
    "+\n",
    "(1-\\theta)\n",
    "\\begin{pmatrix}\n",
    "b(t^{0}) \\\\\n",
    "b(t^{1}) \\\\\n",
    "b(t^{2}) \\\\\n",
    "b(t^{3}) \\\\\n",
    "\\end{pmatrix}\n",
    "+\n",
    "\\begin{pmatrix}\n",
    "q^{0}/\\Delta t + (1-\\theta)\\lambda q^{0} \\\\ 0 \\\\ 0 \\\\ 0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "## Implementing the all-at-once system\n",
    "\n",
    "We start as for the serial method by defining the problem parameters. This time we will need a vector for the time at each timestep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee14b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "T = 102.4\n",
    "nt = 1024\n",
    "dt = T/nt\n",
    "theta = 0.5\n",
    "lamda = -0.01 + 1.0j\n",
    "q0 = 1\n",
    "\n",
    "time = np.linspace(dt, nt*dt, num=nt, endpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6631a7",
   "metadata": {},
   "source": [
    "We will define the right hand side vector $\\textbf{b}$ before tackling the all-at-once Jacobian $\\textbf{A}$. The forcing function is identical to the serial implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28856c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def b(t):\n",
    "    bb = 0\n",
    "    bb += 2*np.exp(-(t-9.5)*(t-9.5))\n",
    "    bb += 0.5*np.exp(-(t-21.3)*(t-21.3)/4)\n",
    "    bb += -5*np.exp(-(t-48.7)*(t-48.7)/9)\n",
    "    return bb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d587e",
   "metadata": {},
   "source": [
    "The forcing terms in the right hand side vector are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9485381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhs = np.zeros(nt, dtype=complex)\n",
    "rhs[:] += theta*b(time[:])\n",
    "rhs[0] += (1-theta)*b(0)\n",
    "rhs[1:] += (1-theta)*b(time[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd95477d",
   "metadata": {},
   "source": [
    "The initial condition term is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e9d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhs[0] += (1/dt + (1-theta)*lamda)*q0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f96c904",
   "metadata": {},
   "source": [
    "Now we can move on to matrices on the left hand side. Toeplitz matrices can be represented using two vectors, one for the first column and one for the first row. For the lower triangular timestepping matrices $\\textbf{B}_{1,2}$ these are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c829a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1col = np.zeros(nt, dtype=complex)\n",
    "b1col[0] = 1\n",
    "b1col[1] = -1\n",
    "\n",
    "b1row = np.zeros_like(b1col)\n",
    "b1row[0] = b1col[0]\n",
    "\n",
    "b2col = np.zeros(nt, dtype=complex)\n",
    "b2col[0] = theta\n",
    "b2col[1] = 1-theta\n",
    "\n",
    "b2row = np.zeros_like(b2col)\n",
    "b2row[0] = b2col[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78fcf9d",
   "metadata": {},
   "source": [
    "Now we can define the Toeplitz Jacobian matrix $\\textbf{A}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdcadbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "acol = b1col/dt - b2col*lamda\n",
    "arow = b1row/dt - b2row*lamda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec42c8c",
   "metadata": {},
   "source": [
    "We will make use of SciPy's sparse linear algebra module. One component we will be using a lot is the [`LinearOperator`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) base class, which is an abstract class representing the action of a matrix on a vector. A class inheriting from `LinearOperator` must implement the `_matvec` method which applies the action of the matrix. This interface means that the matrix does not have to be stored explicitly. Many of SciPy's iterative sparse linear algebra utilities expect a `LinearOperator` instead of the explicit matrix.\n",
    "\n",
    "The first `LinearOperator` we will create is for the all-at-once Jacobian $\\textbf{A}$. We will make use of the SciPy function [`matmul_toeplitz`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.matmul_toeplitz.html) which does an efficient matrix multiplication for Toeplitz matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d6de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "import scipy.sparse.linalg as spla\n",
    "\n",
    "class ToeplitzLinearOperator(spla.LinearOperator):\n",
    "    def __init__(self, col, row):\n",
    "        self.dtype = col.dtype\n",
    "        self.shape = tuple((len(col), len(row)))\n",
    "        self.mat = tuple((col, row))\n",
    "\n",
    "    def _matvec(self, v):\n",
    "        return linalg.matmul_toeplitz(self.mat, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f836f8",
   "metadata": {},
   "source": [
    "The `dtype` and `shape` members are a required part of the `LinearOperator` interface.\n",
    "Now we can define the all-at-once Jacobian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8634ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ToeplitzLinearOperator(acol, arow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c552074a",
   "metadata": {},
   "source": [
    "As a first attempt at solving the all-at-once system we will blindly use [GMRES](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.gmres.html) with no preconditioner. Because we have defined the Jacobian as a `LinearOperator` we can use SciPy's GMRES implementation. At each iteration we will print out the iteration number and the residual `pr_norm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc8f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "niterations=0\n",
    "def gmres_callback(pr_norm):\n",
    "    global niterations\n",
    "    niterations+=1\n",
    "    print(f\"niterations: {str(niterations).rjust(5,' ')} | residual: {pr_norm}\")\n",
    "    return\n",
    "\n",
    "y, exit_code = spla.gmres(A, rhs,\n",
    "                          callback=gmres_callback,\n",
    "                          callback_type='pr_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe8e4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"gmres exit code: {exit_code}\")\n",
    "print(f\"gmres iterations: {niterations}\")\n",
    "print(f\"residual: {linalg.norm(rhs-A.matvec(y))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520564a4",
   "metadata": {},
   "source": [
    "Clearly this is an incredibly inefficient solution strategy! In the rest of this notebook we will create an effective preconditioner for the all-at-once Jacobian using diagonalisation.\n",
    "\n",
    "_You may have noticed that it took more than $N_{t}$ iterations for GMRES to converge, even though this method should converge in at most $n$ iterations for an $n\\times n$ matrix. This is because SciPy uses a restarted GMRES method with a restart of 20 iterations by default. You can change this using the `restart` kwarg. The `rtol` and `atol` kwargs can also be used to control the solver tolerance._\n",
    "\n",
    "The first preconditioner will be a circulant matrix, which are often good preconditioners for Toeplitz matrices (especially triangular Toeplitz matrices). The circulated version of the all-at-once matrix is:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    " 1 &  0 &  0 & -1 \\\\\n",
    "-1 &  1 &  0 & 0 \\\\\n",
    " 0 & -1 &  1 & 0 \\\\\n",
    " 0 &  0 & -1 & 1 \\\\\n",
    "\\end{pmatrix}\n",
    "\\frac{1}{\\Delta t}\n",
    "-\n",
    "\\begin{pmatrix}\n",
    "\\theta     & 0          & 0          & (1-\\theta) \\\\\n",
    "(1-\\theta) & \\theta     & 0          & 0 \\\\\n",
    "0          & (1-\\theta) & \\theta     & 0 \\\\\n",
    "0          & 0          & (1-\\theta) & \\theta \\\\\n",
    "\\end{pmatrix}\n",
    "\\lambda\n",
    "=\n",
    "\\textbf{C}_{1}\\frac{1}{\\Delta t} - \\textbf{C}_{2}\\lambda\n",
    "$$\n",
    "\n",
    "Which is the all-at-once Jacobian obtained for a time-periodic problem with period `T`. All circulant matrices are simultaneously diagonalisable using the discrete fourier transform (DFT) matrix:\n",
    "\n",
    "$$\n",
    "\\textbf{C} = \\textbf{V}\\textbf{D}\\textbf{V}^{-1},\n",
    "\\quad\\quad\n",
    "\\textbf{D} = \\textbf{V}^{-1}\\textbf{C}[:,0]\n",
    "$$\n",
    "\n",
    "Where $\\textbf{V}^{-1}=\\textbf{F}$ is the DFT matrix, and $\\textbf{D}$ is the (diagonal) matrix of eigenvalues which are calculated as the Fourier transform of the first column of $\\textbf{C}$.\n",
    "The inverse of a circulant matrix is $\\textbf{C}^{-1}=\\textbf{V}\\textbf{D}^{-1}\\textbf{V}^{-1}$ which can be efficiently calculated in three steps:\n",
    "1. Multiplying by the inverse eigenvector matrix (i.e. an FFT)\n",
    "2. Dividing by the eigenvalue matrix\n",
    "3. Multiplying by the eigenvector matrix (i.e. an IFFT)\n",
    "\n",
    "We are now ready to implement our circulant preconditioner. SciPy's GMRES routine will take a `LinearOperator` to use as a preconditioner, so this is what we will create. Finish the class skeleton below by completing the `__init__` method and filling out the `_matvec` method using the steps listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e207a5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, ifft\n",
    "\n",
    "class CirculantLinearOperator(spla.LinearOperator):\n",
    "    def __init__(self, col):\n",
    "        self.dtype = col.dtype\n",
    "        self.shape = tuple((len(col), len(col)))\n",
    "        self.col = col\n",
    "        self.eigvals = fft(col, norm='backward')\n",
    "\n",
    "    def _matvec(self, v):\n",
    "        return ifft(fft(v)/self.eigvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8200d117",
   "metadata": {},
   "source": [
    "Now time to test out our new preconditioner by trying to solve the all-at-once system again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f5c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = CirculantLinearOperator(acol)\n",
    "\n",
    "niterations=0\n",
    "\n",
    "y, exit_code = spla.gmres(A, rhs, M=P,\n",
    "                          callback=gmres_callback,\n",
    "                          callback_type='pr_norm')\n",
    "\n",
    "print(f\"gmres exit code: {exit_code}\")\n",
    "print(f\"gmres iterations: {niterations}\")\n",
    "print(f\"residual: {linalg.norm(rhs-A.matvec(y))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f652eec0",
   "metadata": {},
   "source": [
    "What an improvement! The system is now solved almost to machine precision after two iterations. Clearly the circulant matrix is a very effective preconditioner for the all-at-once system of the Dalhquist equation. However, notice that the residual is not particularly small at the first iteration, then plummets at the second. Can we do better?\n",
    "\n",
    "_Trying to do better than two iterations might seem unnecessary, but once we move on to solving PDEs the iteration counts will not be as low, and a better preconditioner will have a more significant effect._ \n",
    "\n",
    "_It is possible to show that GMRES for the all-at-once system of a linear scalar ODE preconditioned by the circulant matrix will converge in at most two iterations. Why is this?_\n",
    "\n",
    "Before trying the next preconditioner, we should check that the solution looks as we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175328a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(time, y.real)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083b1ec",
   "metadata": {},
   "source": [
    "$\\alpha$-circulant matrices are very similar to circulant matrices, except that the circulant entries are scaled by a small parameter $\\alpha\\in(0,1]$. For our all-at-once system this will look like:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    " 1 &  0 &  0 & -\\alpha \\\\\n",
    "-1 &  1 &  0 & 0 \\\\\n",
    " 0 & -1 &  1 & 0 \\\\\n",
    " 0 &  0 & -1 & 1 \\\\\n",
    "\\end{pmatrix}\n",
    "\\frac{1}{\\Delta t}\n",
    "-\n",
    "\\begin{pmatrix}\n",
    "\\theta     & 0          & 0          & \\alpha(1-\\theta) \\\\\n",
    "(1-\\theta) & \\theta     & 0          & 0 \\\\\n",
    "0          & (1-\\theta) & \\theta     & 0 \\\\\n",
    "0          & 0          & (1-\\theta) & \\theta \\\\\n",
    "\\end{pmatrix}\n",
    "\\lambda\n",
    "=\n",
    "\\textbf{C}^{(\\alpha)}_{1}\\frac{1}{\\Delta t} - \\textbf{C}^{(\\alpha)}_{2}\\lambda\n",
    "$$\n",
    "\n",
    "Clearly the standard circulant matrix is recovered when $\\alpha=1$. Fortunately for us, just like the standard circulant matrices all $\\alpha$-circulant matrices with the same $\\alpha$ can be simultaneously diagonalised. The eigendecomposition is still known analytically but is slightly more complicated:\n",
    "\n",
    "$$\n",
    "\\textbf{C}^{(\\alpha)} = \\textbf{V}\\textbf{D}\\textbf{V}^{-1}\n",
    "$$\n",
    "where:\n",
    "$$\n",
    "\\textbf{V}^{-1} = \\textbf{F}\\Gamma_{\\alpha},\n",
    "\\quad\n",
    "\\textbf{D} = \\textbf{F}\\Gamma_{\\alpha}\\textbf{C}[:,0]\n",
    "$$\n",
    "and $\\Gamma_{\\alpha}$ is the diagonal matrix:\n",
    "$$\n",
    "\\Gamma_{\\alpha} = \\text{diag}\\left(\\alpha^{\\frac{k-1}{N_{t}}}\\right)\\; \\forall k \\in [1, N_{t}]\n",
    "$$\n",
    "\n",
    "To use this matrix as a preconditioner we will again create a `LinearOperator`. Complete the class skeleton below by finishing the `__init__` method and implementing the `_matvec` method using the three steps above but with the modified eigenvectors and eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d271a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaCirculantLinearOperator(spla.LinearOperator):\n",
    "    def __init__(self, col, alpha=1):\n",
    "        self.dtype = col.dtype\n",
    "        n = len(col)\n",
    "        self.shape = tuple((n, n))\n",
    "        # delete below here\n",
    "        self.alpha = alpha\n",
    "        self.col = col         \n",
    "\n",
    "        # fft weighting\n",
    "        self.gamma = alpha**(np.arange(n)/n)\n",
    "\n",
    "        # eigenvalues\n",
    "        self.eigvals = fft(col*self.gamma, norm='backward')\n",
    "\n",
    "    def _to_eigvecs(self, v): \n",
    "        return fft(v*self.gamma, norm='ortho')\n",
    "\n",
    "    def _from_eigvecs(self, v): \n",
    "        return ifft(v, norm='ortho')/self.gamma                            \n",
    "\n",
    "    def _matvec(self, v): \n",
    "        return self._from_eigvecs(self._to_eigvecs(v)/self.eigvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2323867d",
   "metadata": {},
   "source": [
    "Now we can try out our new preconditioner. We can pick some small value of $\\alpha$ and see how the preconditioner performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae14db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "\n",
    "Pa = AlphaCirculantLinearOperator(acol, alpha)\n",
    "\n",
    "niterations=0\n",
    "\n",
    "y, exit_code = spla.gmres(A, rhs, M=Pa,\n",
    "                          callback=gmres_callback,\n",
    "                          callback_type='pr_norm')\n",
    "\n",
    "print(f\"gmres exit code: {exit_code}\")\n",
    "print(f\"gmres iterations: {niterations}\")\n",
    "print(f\"residual: {linalg.norm(rhs-A.matvec(y))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963689f0",
   "metadata": {},
   "source": [
    "The solver again converges in two iterations, as expected for the case of a linear scalar ODE, but this time the residual at the first iteration is much smaller. Try different values of $\\alpha$ and see how this affects the residuals. You might have to reduce the `rtol` and `atol` to make sure two iterations are still carried out.\n",
    "Some other questions you could look into are:\n",
    "- What does a plot of the residual after one iteration vs $\\alpha$ look like?\n",
    "- What happens when $\\alpha$ approaches machine zero?\n",
    "- What happens if you change the problem parameters, e.g. `nt`, `dt`, `lamda`?\n",
    "\n",
    "_You should check your implementation of the $\\alpha$-circulant operator by setting `alpha=1` and verifying that you get the same residuals as with the standard circulant operator above. This doesn't rule out all mistakes but is still good to do._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed39bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
